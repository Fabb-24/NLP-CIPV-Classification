{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c02d714",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e3be5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import getpass\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from util import get_root_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67be8af",
   "metadata": {},
   "source": [
    "# 1. Test conversation for binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe997f4",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5936c152",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "API_KEY = getpass.getpass(\"Enter your Google AI Studio API key: \").strip()\n",
    "DATASET_PATH = os.path.join(get_root_path(), \"dataset\", \"merged_conversation.csv\")\n",
    "JSON_OUTPUT_PATH = os.path.join(get_root_path(), \"dataset\", \"inference_test_binary.json\")\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1838462b",
   "metadata": {},
   "source": [
    "### Prompt and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5538ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_binary_examples():\n",
    "    \"\"\"\n",
    "    Extract 5 toxic and 5 non-toxic conversation examples from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the toxic and non-toxic examples.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    examples = []\n",
    "\n",
    "    # shuffle dataset\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # get first 5 toxic conversation\n",
    "    toxic_examples = df[df['toxic'] == \"Si\"].head(5)\n",
    "    examples.extend({'toxic': row['toxic'], 'conversation': row['conversation']} for _, row in toxic_examples.iterrows())\n",
    "\n",
    "    # get first 5 nontoxic conversation\n",
    "    nontoxic_examples = df[df['toxic'] == \"No\"].head(5)\n",
    "    examples.extend({'toxic': row['toxic'], 'conversation': row['conversation']} for _, row in nontoxic_examples.iterrows())\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "Genera 10 conversazioni (5 tossiche e 5 non tossiche) a partire dagli esempi forniti.\n",
    "\n",
    "Vincoli:\n",
    "- Ogni conversazione deve avere tra i 5 e i 10 turni, con numero variabile. Devono essere realistiche e naturali.\n",
    "- La risposta deve essere esclusivamente un array JSON valido, senza testo introduttivo o commenti. Solo JSON puro, senza usare blocchi di codice come ```json o ```.\n",
    "\n",
    "Il formato di ogni oggetto nell’array è:\n",
    "\n",
    "{\n",
    "    \"person_couple\": \"<etichetta della coppia tossica, oppure 'null' se la conversazione è non tossica>\",\n",
    "    \"name1\": \"<nome del primo interlocutore>\",\n",
    "    \"name2\": \"<nome del secondo interlocutore>\",\n",
    "    \"explaination\": \"<per le tossiche: breve descrizione della dinamica tossica; per le non tossiche: breve descrizione dell’argomento della conversazione>\",\n",
    "    \"toxic\": \"Si\"/\"No\",\n",
    "    \"conversation\": [\n",
    "        {\"speaker\": \"<name1>\", \"text\": \"<frase>\"},\n",
    "        {\"speaker\": \"<name2>\", \"text\": \"<frase>\"},\n",
    "        ...\n",
    "    ]\n",
    "}\n",
    "\n",
    "Ulteriori vincoli:\n",
    "- 5 conversazioni devono essere tossiche, 5 non tossiche.\n",
    "- Ogni conversazione deve essere in italiano, con tono naturale.\n",
    "- Usa sempre coppie di nomi italiani diversi e realistici (non ripetere nomi già usati).\n",
    "- Il JSON deve essere perfettamente valido e parsabile, senza errori di sintassi né virgole superflue.\n",
    "\n",
    "Esempi di conversazioni tossiche e non tossiche:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# ---- Add examples to prompt ----\n",
    "examples = extract_binary_examples()\n",
    "for example in examples:\n",
    "    PROMPT += f\"\"\"\n",
    "    - {\"Toxic\" if example['toxic'] == \"Si\" else \"Non Toxic\"}: {example['conversation']} \\n\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca56e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] Generating conversation with model {MODEL_NAME}...\")\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME,\n",
    "    contents=PROMPT\n",
    ")\n",
    "json_text = response.text.strip()\n",
    "\n",
    "# ---- Save the JSON output to a file ----\n",
    "with open(JSON_OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json.loads(json_text), f, ensure_ascii=False, indent=4)\n",
    "    print(f\"[INFO] Conversation JSON saved to {JSON_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6806d1",
   "metadata": {},
   "source": [
    "# 2. Test conversation for multiclass classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad96914",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b7182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"gemini-2.5-pro\"\n",
    "API_KEY = getpass.getpass(\"Enter your Google AI Studio API key: \").strip()\n",
    "DATASET_PATH = os.path.join(get_root_path(), \"dataset\", \"toxic_conversation.csv\")\n",
    "JSON_OUTPUT_PATH = os.path.join(get_root_path(), \"dataset\", \"inference_test_multiclass.json\")\n",
    "\n",
    "client = genai.Client(api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b11704",
   "metadata": {},
   "source": [
    "### Prompt and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99dc7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_examples():\n",
    "    \"\"\"\n",
    "    Extract the first example from each couple.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the first example from each couple.\n",
    "    \"\"\"\n",
    "\n",
    "    df = pd.read_csv(DATASET_PATH)\n",
    "    examples = []\n",
    "\n",
    "    # extract the first example from each couple\n",
    "    for couple in df[\"person_couple\"].unique():\n",
    "        example = df[df[\"person_couple\"] == couple].iloc[0]\n",
    "        examples.append({\n",
    "            \"person_couple\": example[\"person_couple\"],\n",
    "            \"conversation\": example[\"conversation\"]\n",
    "        })\n",
    "        \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24eac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "    Genera esattamente 10 conversazioni tossiche in lingua italiana, ciascuna appartenente a una delle seguenti classi di dinamica relazionale tossica (una conversazione per ogni classe):\n",
    "    - Psicopatico e Adulatrice  \n",
    "    - Manipolatore e Dipendente emotiva  \n",
    "    - Persona violenta e Succube  \n",
    "    - Narcisista e Succube  \n",
    "    - Dominante e Schiavo emotivo  \n",
    "    - Sadico-Crudele e Masochista  \n",
    "    - Perfezionista Critico e Insicura Cronica  \n",
    "    - Vittimista e Crocerossina  \n",
    "    - Controllore e Isolata  \n",
    "    - Geloso-Ossessivo e Sottomessa\n",
    "\n",
    "    Vincoli:\n",
    "    - Ogni conversazione deve avere un numero di turni variabile, ma deve contenere tra i 5 e i 10 turni.\n",
    "    - La risposta deve essere esclusivamente un array JSON valido, senza spiegazioni, testo introduttivo o commenti. Solo JSON puro, senza usare blocchi di codice come ```json o ```.\n",
    "\n",
    "    Il formato di ogni oggetto nell’array è:\n",
    "\n",
    "    {\n",
    "        \"person_couple\": \"<etichetta della coppia tossica>\",\n",
    "        \"name1\": \"<nome del primo interlocutore>\",\n",
    "        \"name2\": \"<nome del secondo interlocutore>\",\n",
    "        \"explaination\": \"<breve spiegazione (1–2 frasi in italiano) della dinamica tossica mostrata nella conversazione>\",\n",
    "        \"toxic\": \"Si\",\n",
    "        \"conversation\": [\n",
    "            {\"speaker\": \"<name1>\", \"text\": \"<frase>\"},\n",
    "            {\"speaker\": \"<name2>\", \"text\": \"<frase>\"},\n",
    "            ...\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    Ulteriori vincoli:\n",
    "    - Genera esattamente 10 conversazioni, una per ciascuna delle classi elencate.\n",
    "    - Usa nomi italiani realistici e diversi per ogni conversazione (nessun nome deve ripetersi).\n",
    "    - Le conversazioni devono essere realistiche e rappresentative delle dinamiche tossiche indicate.\n",
    "    - Il JSON deve essere perfettamente valido e parsabile, senza commenti, testo extra o virgole finali.\n",
    "\n",
    "    Esempi di conversazioni tossiche:\n",
    "\"\"\"\n",
    "\n",
    "# ---- Add examples to prompt ----\n",
    "examples = extract_examples()\n",
    "for example in examples:\n",
    "    PROMPT += f\"\"\"\n",
    "    - {example['person_couple']}: {example['conversation']}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c16692",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"[INFO] Generating conversation with model {MODEL_NAME}...\")\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_NAME,\n",
    "    contents=PROMPT\n",
    ")\n",
    "print(response)\n",
    "json_text = response.text.strip()\n",
    "print(json_text)\n",
    "\n",
    "# ---- Save the JSON output to a file ----\n",
    "with open(JSON_OUTPUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(json.loads(json_text), f, ensure_ascii=False, indent=4)\n",
    "    print(f\"[INFO] Conversation JSON saved to {JSON_OUTPUT_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
